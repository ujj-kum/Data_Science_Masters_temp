{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d91ea3f-a7ff-4a52-a881-e6a2d0253f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8478ba-f8ad-418e-8bfe-ef031b1735a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['recurrent neural network #@!',\n",
    "\t\t'neural network @',\n",
    "\t\t'artificial neural',\n",
    "\t\t'connections between nodes',\n",
    "\t\t'can create a cycle',\n",
    "\t\t'allowing output',\n",
    "\t\t'some nodes to affect subsequent',\n",
    "\t\t'exhibit temporal',\n",
    "\t\t'dynamic behavior',\n",
    "\t\t'type of Neural Network',\n",
    "    'affect subsequent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c666a73d-0aa4-40f1-9865-0010d215c1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.13.1 in /opt/conda/lib/python3.10/site-packages (2.13.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (65.5.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (0.37.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (3.7.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (2.13.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (1.16.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (1.23.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (22.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (4.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (2.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (2.13.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (1.66.1)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (18.1.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (24.3.25)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (4.21.11)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (2.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.13.1) (0.38.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (0.7.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.34.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.0.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (5.5.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.13.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b358a45-bf82-4505-83d2-45bd8844b2c7",
   "metadata": {},
   "source": [
    "### Above tensorflow 2.2, keras is available as wrapper over tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7beddf4-7a56-41c9-a899-cd9145cb2add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.13.1 in /opt/conda/lib/python3.10/site-packages (2.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras==2.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35b3067-5266-4f73-9aed-8485160773bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39m__version__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/__init__.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5b552-f938-432f-ac80-540842957237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c4fbd-dd3f-4f11-bcfe-c2d6d444a161",
   "metadata": {},
   "source": [
    "### Performing tokenization\n",
    "\n",
    "**tf.keras.layers.TextVectorization** is used now\n",
    "\n",
    "Here any OOV token will be assigned \\<UNK>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458434a0-a79a-4f09-abbe-36c37d3e6eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<UNK>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b081fe56-d8ca-4ca4-8624-e471f299874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ed5c9-966d-4560-8f2d-b12cd3beccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5635dde-fb6d-43f0-b47f-d606663c740f",
   "metadata": {},
   "source": [
    "### 0 isn't used for index because it is used for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd026f62-a967-4de2-a317-98d1f7dce782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking index for each word\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582764d9-81bb-4aaa-8760-5ec920eafe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting no. of sentences\n",
    "tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde1ba53-0de1-4f64-a9ae-1cdd552eb510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting each word to a token id\n",
    "# Each word is replaced by its index in the generated vocubalary as its token id\n",
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a30e4-3db2-4ddd-abbc-4c86040a44cd",
   "metadata": {},
   "source": [
    "### Perform padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c120fc5-58c2-4013-b26a-9468baa625b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes every sentence length equal to maxlen\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "n_sequences = pad_sequences(sequences=sequences, maxlen=10, padding='post')\n",
    "n_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557e6f5d-c02b-447e-a571-0c7ef29398d9",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f5fbf3-b56e-4d71-9ddf-f6a1aa5d644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "data = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4d0862-3639-464c-84aa-e7b588bdc0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(data).shape, type(data), len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d6eff4-a216-4585-b01d-e69cf87f001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of movies = {len(data[0][0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887226a7-6008-494c-ba9e-b30ca0e87591",
   "metadata": {},
   "source": [
    "### Loading in splitted format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4f3e6b-db56-4e44-b48c-e8d5d19f6f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e5bc4-af20-42cd-a908-946f05a21f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_train), type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f77a858-d823-48cb-809d-6f5ffe7a6f50",
   "metadata": {},
   "source": [
    "X_train and X_test are 2D array having no. of rows=25000 and no. of columns vary. Since the reviews are of different lengths, the dataset is loaded as a 1D array of lists, not as a 2D matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca5e59-1d7d-4af5-bbf7-134ef3faa556",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e4425-aa90-414d-81da-df749c476fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max number of words in a sentence\n",
    "num_words = 0\n",
    "for i in range(len(X_train)):\n",
    "    num_words = max(num_words, len(X_train[i]))\n",
    "\n",
    "num_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de08cba0-be68-42a0-aa8f-3e13ea6c5268",
   "metadata": {},
   "source": [
    "### Perform padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e991a78-ce14-4d16-9d80-8fce2d555bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(sequences=X_train, maxlen=num_words, padding='post')\n",
    "X_test = pad_sequences(sequences=X_test, maxlen=num_words, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09250d5d-ea86-4641-a068-cbff0627ff08",
   "metadata": {},
   "source": [
    "### Build model\n",
    "- for Seq 2 Seq data, we use **Sequential**\n",
    "-----\n",
    "##### Visualizing RNN model\n",
    "- **return_sequences** return whether RNN should return full sequence of output for each timesteps(No. of words in a sentence) or only the output from last timestep\n",
    "\n",
    "- If **True**, return shape = (None, #Timesteps, #units)\n",
    "- If **False**, returnn shape = (None, #units)\n",
    "\n",
    "where **None** refers to the batch size\n",
    "\n",
    "---------\n",
    "### Parameters of a RNN\n",
    "- Weights for the input to the hidden state: These are learned weights that map the input data to the hidden state.\n",
    "- Weights for the recurrent connections: These are the weights that connect the hidden state at time t to the hidden state at time t+1.\n",
    "- Biases: Each unit has a bias term.\n",
    "- The formula to calculate the total number of parameters in an RNN is: **RNN Parameters =(units×input size)+(units×units)+units**\n",
    "\n",
    "Here:\n",
    "\n",
    "units = 32\n",
    "input size = 1 (since each time step has only 1 feature)\n",
    "\n",
    "Substituting these values:\n",
    "\n",
    "RNN Parameters=(32×1)+(32×32)+32 = 1088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb0076e-ca69-464b-a6a0-c20355a3ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# units refer to the number of neurons 1 one layer\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Embedding, Flatten\n",
    "\n",
    "# X_train.shape => ((25000, 2494))\n",
    "\n",
    "model = Sequential([\n",
    "SimpleRNN(units=32, input_shape=(X_train.shape[1], 1), return_sequences=False),\n",
    "Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa143c4-dcec-48a1-8d52-f823c3da558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7663438-a1dc-4c23-8c03-badcd6581453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dfb9cb-c49f-4f7b-8680-a4f36a497108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model.h5')\n",
    "# model.save('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae99a4-e1dc-4ec6-8562-e45cc1d425ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.weights)\n",
    "model.load_weights('model.h5')\n",
    "print(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fbb517-bb04-4a0c-8009-68032df66591",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab199d3-508c-46bf-8415-5b7ee8444e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
